# Provider settings - OpenAI, Anthropic, and OpenRouter are supported
PROVIDER=openai

# Base URL for the API
# Example for OpenAI: https://api.openai.com/v1
# Example for Anthropic: https://api.anthropic.com
# Example for OpenRouter: https://openrouter.ai/api/v1
BASE_URL=

# API Key for authentication with the LLM provider
# Get from your provider dashboard
# For OpenRouter: Get from https://openrouter.ai/keys
LLM_API_KEY=

# Model identifier to use (what was previously selected in dropdown)
# OpenAI examples: gpt-4o, gpt-4o-mini, gpt-4-turbo
# Anthropic examples: anthropic/claude-3-sonnet, anthropic/claude-3-opus
# OpenRouter examples: openai/gpt-4-turbo, anthropic/claude-3-haiku, meta-llama/llama-3-70b-instruct
# Note: When using OpenRouter, if you specify a model without a provider prefix (e.g., just "gpt-4o"), 
# the system will automatically prefix it with "openai/" for compatibility
MODEL_CHOICE=

# HTTP Referer - Used for OpenRouter to identify your application
# Required when using OpenRouter to comply with their terms of service
# Default: https://pydantic-ai-mcp-agent.com
HTTP_REFERER=