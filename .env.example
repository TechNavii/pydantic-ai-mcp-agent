# Provider settings - OpenAI, Anthropic, and OpenRouter are supported
PROVIDER=openai

# Base URL for the API
# Example for OpenAI: https://api.openai.com/v1
# Example for Anthropic: https://api.anthropic.com
# Example for OpenRouter: https://openrouter.ai/api/v1
BASE_URL=

# API Key for authentication with the LLM provider
# Get from your provider dashboard
# For OpenRouter: Get from https://openrouter.ai/keys
LLM_API_KEY=

# Model identifier to use (what was previously selected in dropdown)
# OpenAI examples: gpt-4o, gpt-4o-mini, gpt-4-turbo
# Anthropic examples: anthropic/claude-3-sonnet, anthropic/claude-3-opus
# OpenRouter examples (RECOMMENDED): openai/gpt-4-turbo, openai/gpt-3.5-turbo
# OpenRouter alternative models (MAY HAVE COMPATIBILITY ISSUES): 
#   anthropic/claude-3-haiku, meta-llama/llama-3-70b-instruct, google/gemini-1.5-pro
# 
# Note: For best compatibility with OpenRouter, use OpenAI models (openai/...)
# If you specify a model without a provider prefix (e.g., just "gpt-4o"),
# the system will automatically prefix it with "openai/" for compatibility
#
# With OpenRouter, you can leave this empty to let OpenRouter select the 
# best available model automatically (recommended for beginners)
MODEL_CHOICE=